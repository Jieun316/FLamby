{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/dbswldms316/FLamby/')\n",
    "\n",
    "from flamby.datasets.fed_tcga_brca.dataset import TcgaBrcaRaw, FedTcgaBrca\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "mydataset_raw = TcgaBrcaRaw()\n",
    "mydataset_pooled = FedTcgaBrca(train=True, pooled=True)\n",
    "\n",
    "from flamby.datasets.fed_tcga_brca import (\n",
    "    BATCH_SIZE,\n",
    "    LR,\n",
    "    NUM_EPOCHS_POOLED,\n",
    "    Baseline,\n",
    "    BaselineLoss,\n",
    "    metric,\n",
    "    NUM_CLIENTS,\n",
    "    Optimizer,\n",
    ")\n",
    "\n",
    "# class DictDataset(Dataset):\n",
    "#     def __init__(self, data):\n",
    "#         self.data = data\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.keys)\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         key = self.keys[idx]\n",
    "#         return self.data_dict[key]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dbswldms316/FLamby/flamby/datasets/fed_tcga_brca/dataset.py:52: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return (torch.tensor(x, dtype=self.X_dtype), torch.tensor(y, dtype=self.y_dtype))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([60.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  1.,\n",
      "         0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  0.]), tensor([  1., 921.]))\n",
      "** train dataset includes age groups like:  [2, 17, 52, 66, 60, 39, 12]\n",
      "** train dataset after split:  [19, 217, 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dbswldms316/FLamby/flamby/datasets/fed_tcga_brca/dataset.py:52: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return (torch.tensor(x, dtype=self.X_dtype), torch.tensor(y, dtype=self.y_dtype))\n",
      "/home/dbswldms316/FLamby/flamby/datasets/fed_tcga_brca/dataset.py:52: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return (torch.tensor(x, dtype=self.X_dtype), torch.tensor(y, dtype=self.y_dtype))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** test dataset includes age groups like:  [1, 5, 14, 11, 19, 7, 4, 2]\n",
      "** test dataset after split:  [6, 51, 6]\n",
      "[tensor([[29.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n",
      "          0.,  1.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  1.,  1.,  0.,  1.,\n",
      "          0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.]]), tensor([[   0., 3286.]])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.16s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 187.91it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 910.82it/s]\n",
      "/home/dbswldms316/FLamby/flamby/datasets/fed_tcga_brca/dataset.py:52: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return (torch.tensor(x, dtype=self.X_dtype), torch.tensor(y, dtype=self.y_dtype))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for age group 0 to 39: {'client_test_0': 0.5}\n",
      "Results for age group 41 to 79: {'client_test_0': 0.5955056179775281}\n",
      "Results for age group 80 to 100: {'client_test_0': 0.25}\n",
      "(tensor([63.,  1.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
      "         0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,  1.,  0.,\n",
      "         1.,  1.,  1.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.]), tensor([  0., 343.]))\n",
      "** train dataset includes age groups like:  [1, 8, 30, 47, 43, 22, 4, 1]\n",
      "** train dataset after split:  [9, 142, 5]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 39\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Traditional pytorch training loop\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, NUM_EPOCHS_POOLED):\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m X,y \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[1;32m     40\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     41\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model(X)\n",
      "File \u001b[0;32m~/miniconda3/envs/flam/lib/python3.9/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/flam/lib/python3.9/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/flam/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/flam/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/FLamby/flamby/datasets/fed_tcga_brca/dataset.py:50\u001b[0m, in \u001b[0;36mTcgaBrcaRaw.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m---> 50\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     51\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39miloc[idx, \u001b[38;5;241m40\u001b[39m:\u001b[38;5;241m42\u001b[39m]\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39mtensor(x, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_dtype), torch\u001b[38;5;241m.\u001b[39mtensor(y, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_dtype))\n",
      "File \u001b[0;32m~/miniconda3/envs/flam/lib/python3.9/site-packages/pandas/core/indexing.py:1185\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1183\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[0;32m-> 1185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1187\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/flam/lib/python3.9/site-packages/pandas/core/indexing.py:1693\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1691\u001b[0m tup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_tuple_indexer(tup)\n\u001b[1;32m   1692\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m suppress(IndexingError):\n\u001b[0;32m-> 1693\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_lowerdim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1695\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_tuple_same_dim(tup)\n",
      "File \u001b[0;32m~/miniconda3/envs/flam/lib/python3.9/site-packages/pandas/core/indexing.py:1066\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_lowerdim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tup):\n\u001b[1;32m   1063\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_label_like(key):\n\u001b[1;32m   1064\u001b[0m         \u001b[38;5;66;03m# We don't need to check for tuples here because those are\u001b[39;00m\n\u001b[1;32m   1065\u001b[0m         \u001b[38;5;66;03m#  caught by the _is_nested_tuple_indexer check above.\u001b[39;00m\n\u001b[0;32m-> 1066\u001b[0m         section \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1068\u001b[0m         \u001b[38;5;66;03m# We should never have a scalar section here, because\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m         \u001b[38;5;66;03m#  _getitem_lowerdim is only called after a check for\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m         \u001b[38;5;66;03m#  is_scalar_access, which that would be.\u001b[39;00m\n\u001b[1;32m   1071\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m section\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim:\n\u001b[1;32m   1072\u001b[0m             \u001b[38;5;66;03m# we're in the middle of slicing through a MultiIndex\u001b[39;00m\n\u001b[1;32m   1073\u001b[0m             \u001b[38;5;66;03m# revise the key wrt to `section` by inserting an _NS\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/flam/lib/python3.9/site-packages/pandas/core/indexing.py:1721\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1720\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_getitem_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, axis: AxisInt):\n\u001b[0;32m-> 1721\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;43mEllipsis\u001b[39;49m:\n\u001b[1;32m   1722\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1723\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, ABCDataFrame):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Instantiation of local train set (and data loader)), baseline loss function, baseline model, default optimizer\n",
    "#feature_tensor = torch.tensor([[1,10], [2,20], [3,30], [4,40], [5,50], [6,60], [7,70], [8,80],[9,90],[10,100]])\n",
    "for i in [0,1,2,3,4,5]:\n",
    "    train_dataset = FedTcgaBrca(center=i, train=True, pooled=False)\n",
    "    print(train_dataset[0])\n",
    "    age_groups = {}\n",
    "    for person in train_dataset:\n",
    "        age = int(person[0][0])\n",
    "        age_group = int(age - age % 10)\n",
    "        if age_group not in age_groups:\n",
    "            age_groups[age_group] = []\n",
    "        age_groups[age_group].append(person)\n",
    "    age_groups = dict(sorted(age_groups.items()))\n",
    "    \n",
    "    result_dict = {'0 to 30':[], '40 to 60':[], '70 to 100':[]}\n",
    "    for key in age_groups.keys():\n",
    "        if 0 < key <=30:\n",
    "            result_dict['0 to 30']+=(age_groups[key])\n",
    "        elif 30 < key <= 70:\n",
    "            result_dict['40 to 60']+=(age_groups[key])\n",
    "        else:\n",
    "            result_dict['70 to 100']+=(age_groups[key])\n",
    "    print('** train dataset includes age groups like: ', [len(age_groups[i]) for i in age_groups.keys()])\n",
    "    #print(result_dict)\n",
    "    print('** train dataset after split: ', [len(result_dict[i]) for i in result_dict.keys()])\n",
    "    # train_dataset = DictDataset(result_dict)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0)\n",
    "    #train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "    \n",
    "    lossfunc = BaselineLoss()\n",
    "    model = Baseline()\n",
    "    optimizer = Optimizer(model.parameters(), lr=LR)\n",
    "    \n",
    "    \n",
    "    # Traditional pytorch training loop\n",
    "    for epoch in range(0, NUM_EPOCHS_POOLED):\n",
    "        for X,y in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X)\n",
    "            loss = lossfunc(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "    # Evaluation\n",
    "    from flamby.utils import evaluate_model_on_tests\n",
    "    # Instantiation of a list of the local test sets\n",
    "    test_dataset = FedTcgaBrca(center=i, train=False, pooled=False)\n",
    "    age_groups = {}\n",
    "    for person in test_dataset:\n",
    "        age = int(person[0][0])\n",
    "        age_group = age - age % 10\n",
    "        if age_group not in age_groups:\n",
    "            age_groups[age_group] = []\n",
    "        age_groups[age_group].append(person)\n",
    "    age_groups = dict(sorted(age_groups.items()))\n",
    "    \n",
    "    result_dict = {'0 to 30': [], '31 to 70': [], '71 to 100': []}\n",
    "    for key in age_groups.keys():\n",
    "        if key <= 30:\n",
    "            result_dict['0 to 30'] += age_groups[key]\n",
    "        elif key <= 70:\n",
    "            result_dict['31 to 70'] += age_groups[key]\n",
    "        else:\n",
    "            result_dict['71 to 100'] += age_groups[key]\n",
    "\n",
    "    print('** test dataset includes age groups like: ',[len(age_groups[i]) for i in age_groups.keys()])\n",
    "    print('** test dataset after split: ', [len(result_dict[i]) for i in result_dict.keys()])\n",
    "    \n",
    "    # 각 나이 범주에 해당하는 데이터셋 생성\n",
    "    test_dataset_0_to_30 = result_dict['0 to 30']\n",
    "    test_dataset_40_to_60 = result_dict['31 to 70']\n",
    "    test_dataset_70_to_100 = result_dict['71 to 100']\n",
    "\n",
    "    # 각 데이터셋을 DataLoader로 변환\n",
    "    test_dataloader_0_to_30 = torch.utils.data.DataLoader(test_dataset_0_to_30,  shuffle=False)\n",
    "    test_dataloader_40_to_60 = torch.utils.data.DataLoader(test_dataset_40_to_60,  shuffle=False)\n",
    "    test_dataloader_70_to_100 = torch.utils.data.DataLoader(test_dataset_70_to_100,  shuffle=False)\n",
    "    print(next(iter(test_dataloader_0_to_30)))\n",
    "    # evaluate_model_on_tests 함수 호출\n",
    "    with torch.no_grad():\n",
    "        dict_cindex_0_to_30 = evaluate_model_on_tests(model, [test_dataloader_0_to_30], metric)\n",
    "        dict_cindex_40_to_60 = evaluate_model_on_tests(model, [test_dataloader_40_to_60], metric)\n",
    "        dict_cindex_70_to_100 = evaluate_model_on_tests(model, [test_dataloader_70_to_100], metric)\n",
    "\n",
    "    # 결과 출력\n",
    "    print(\"Results for age group 0 to 39:\", dict_cindex_0_to_30)\n",
    "    print(\"Results for age group 41 to 79:\", dict_cindex_40_to_60)\n",
    "    print(\"Results for age group 80 to 100:\", dict_cindex_70_to_100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
