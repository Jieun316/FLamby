{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([ 63.0000,   1.0000, 145.0000, 233.0000,   1.0000, 150.0000,   0.0000,\n",
      "          2.3000,   0.0000,   0.0000,   0.0000,   0.0000,   1.0000]), tensor([0.]))\n",
      "(tensor([ 63.0000,   1.0000, 145.0000, 233.0000,   1.0000, 150.0000,   0.0000,\n",
      "          2.3000,   0.0000,   0.0000,   0.0000,   0.0000,   1.0000]), tensor([0.]))\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/dbswldms316/FLamby/')\n",
    "\n",
    "from flamby.datasets.fed_heart_disease.dataset import HeartDiseaseRaw, FedHeartDisease\n",
    "\n",
    "mydataset_raw = HeartDiseaseRaw()\n",
    "print(mydataset_raw[0])\n",
    "mydataset_pooled = FedHeartDisease(train=True, pooled=True)\n",
    "print(mydataset_pooled[0])\n",
    "\n",
    "from flamby.datasets.fed_heart_disease import (\n",
    "    BATCH_SIZE,\n",
    "    LR,\n",
    "    NUM_EPOCHS_POOLED,\n",
    "    Baseline, \n",
    "    BaselineLoss,\n",
    "    metric,\n",
    "    NUM_CLIENTS,\n",
    "    Optimizer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([ 56.0000,   1.0000, 120.0000, 236.0000,   0.0000, 178.0000,   0.0000,\n",
      "          0.8000,   1.0000,   0.0000,   0.0000,   0.0000,   0.0000]), tensor([0.]))\n",
      "** test dataset includes age groups like:  [19, 65, 106, 55, 9]\n",
      "** test dataset after split:  [19, 226, 9]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Instantiation of a list of the local test sets\n",
    "test_dataset = FedHeartDisease(train=False, pooled=True)\n",
    "age_groups = {}\n",
    "print(test_dataset[0])\n",
    "for person_idx in range(len(test_dataset)):\n",
    "    person = test_dataset[person_idx]\n",
    "    age = int(person[0][0])\n",
    "    age_group = age - age % 10\n",
    "    if age_group not in age_groups:\n",
    "        age_groups[age_group] = []\n",
    "    age_groups[age_group].append(person)\n",
    "age_groups = dict(sorted(age_groups.items()))\n",
    "\n",
    "result_dict = {'0 to 30': [], '40 to 60': [], 'rest':[]}\n",
    "for key in age_groups.keys():\n",
    "    if key <= 30:\n",
    "        result_dict['0 to 30'] += age_groups[key]\n",
    "    elif 40 <= key <= 60:\n",
    "        result_dict['40 to 60'] += age_groups[key]\n",
    "    else:\n",
    "        result_dict['rest'] += age_groups[key]\n",
    "\n",
    "print('** test dataset includes age groups like: ',[len(age_groups[i]) for i in age_groups.keys()])\n",
    "print('** test dataset after split: ', [len(result_dict[i]) for i in result_dict.keys()])\n",
    "\n",
    "# 각 나이 범주에 해당하는 데이터셋 생성\n",
    "test_dataset_0_to_30 = result_dict['0 to 30']\n",
    "test_dataset_40_to_100 = result_dict['40 to 60']\n",
    "test_dataset_70_to_100 = result_dict['rest']\n",
    "\n",
    "# 각 데이터셋을 DataLoader로 변환\n",
    "test_dataloader_0_to_30 = torch.utils.data.DataLoader(test_dataset_0_to_30,  shuffle=False)\n",
    "test_dataloader_40_to_100 = torch.utils.data.DataLoader(test_dataset_40_to_100,  shuffle=False)\n",
    "test_dataloader_70_to_100 = torch.utils.data.DataLoader(test_dataset_70_to_100,  shuffle=False)\n",
    "#print(next(iter(test_dataloader_0_to_30)))\n",
    "# evaluate_model_on_tests 함수 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199\n",
      "** train dataset includes age groups like:  [1, 11, 47, 81, 56, 3]\n",
      "** train dataset after split:  [12, 187, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.07s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 47.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 749.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for age group 0 to 39: {'client_test_0': 0.2631578947368421}\n",
      "Results for age group 40 to 69: {'client_test_0': 0.5442477876106194}\n",
      "Results for age group rest: {'client_test_0': 0.3333333333333333}\n",
      "172\n",
      "** train dataset includes age groups like:  [2, 30, 61, 73, 6]\n",
      "** train dataset after split:  [32, 140, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 463.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 26.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 559.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for age group 0 to 39: {'client_test_0': 0.6842105263157895}\n",
      "Results for age group 40 to 69: {'client_test_0': 0.6858407079646017}\n",
      "Results for age group rest: {'client_test_0': 0.7777777777777778}\n",
      "30\n",
      "** train dataset includes age groups like:  [2, 3, 11, 11, 3]\n",
      "** train dataset after split:  [2, 28, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 344.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 42.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 692.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for age group 0 to 39: {'client_test_0': 0.2631578947368421}\n",
      "Results for age group 40 to 69: {'client_test_0': 0.5442477876106194}\n",
      "Results for age group rest: {'client_test_0': 0.3333333333333333}\n",
      "85\n",
      "** train dataset includes age groups like:  [1, 6, 33, 37, 8]\n",
      "** train dataset after split:  [1, 84, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 507.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 51.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 772.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for age group 0 to 39: {'client_test_0': 0.7368421052631579}\n",
      "Results for age group 40 to 69: {'client_test_0': 0.4778761061946903}\n",
      "Results for age group rest: {'client_test_0': 0.3333333333333333}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Instantiation of local train set (and data loader)), baseline loss function, baseline model, default optimizer\n",
    "#feature_tensor = torch.tensor([[1,10], [2,20], [3,30], [4,40], [5,50], [6,60], [7,70], [8,80],[9,90],[10,100]])\n",
    "for i in [0,1,2,3]:\n",
    "    train_dataset = FedHeartDisease(center=i, train=True, pooled=False)\n",
    "    print(len(train_dataset))\n",
    "    #print(len(train_dataset))\n",
    "    age_groups = {}\n",
    "    for person_idx in range(len(train_dataset)):\n",
    "        person = train_dataset[person_idx]\n",
    "        age = int(person[0][0])\n",
    "        age_group = int(age - age % 10)\n",
    "        if age_group not in age_groups:\n",
    "            age_groups[age_group] = []\n",
    "        age_groups[age_group].append(person)\n",
    "    age_groups = dict(sorted(age_groups.items()))\n",
    "    \n",
    "    result_dict = {'0 to 30':[], '40 to 60':[], '70 to 100':[]}\n",
    "    for key in age_groups.keys():\n",
    "        if 0 < key <=30:\n",
    "            result_dict['0 to 30']+=(age_groups[key])\n",
    "        elif 30 < key <= 70:\n",
    "            result_dict['40 to 60']+=(age_groups[key])\n",
    "        else:\n",
    "            result_dict['70 to 100']+=(age_groups[key])\n",
    "    print('** train dataset includes age groups like: ', [len(age_groups[i]) for i in age_groups.keys()])\n",
    "    #print(result_dict)\n",
    "    print('** train dataset after split: ', [len(result_dict[i]) for i in result_dict.keys()])\n",
    "    # train_dataset = DictDataset(result_dict)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0)\n",
    "    #train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "    \n",
    "    lossfunc = BaselineLoss()\n",
    "    local_model = Baseline()\n",
    "    optimizer = Optimizer(local_model.parameters(), lr=LR)\n",
    "    \n",
    "    \n",
    "    # Traditional pytorch training loop\n",
    "    for epoch in range(0, NUM_EPOCHS_POOLED):\n",
    "        for X,y in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = local_model(X)\n",
    "            loss = lossfunc(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Evaluation\n",
    "    from flamby.utils import evaluate_model_on_tests\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        dict_cindex_0_to_30 = evaluate_model_on_tests(local_model, [test_dataloader_0_to_30], metric)\n",
    "        dict_cindex_40_to_60 = evaluate_model_on_tests(local_model, [test_dataloader_40_to_100], metric)\n",
    "        dict_cindex_70_to_100 = evaluate_model_on_tests(local_model, [test_dataloader_70_to_100], metric)\n",
    "\n",
    "    # 결과 출력\n",
    "    print(\"Results for age group 0 to 39:\", dict_cindex_0_to_30)\n",
    "    print(\"Results for age group 40 to 69:\", dict_cindex_40_to_60)\n",
    "    print(\"Results for age group rest:\", dict_cindex_70_to_100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 260.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'client_test_0': 0.46153846153846156}\n",
      "172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 302.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'client_test_0': 0.3707865168539326}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 742.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'client_test_0': 0.9375}\n",
      "85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 430.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'client_test_0': 0.7111111111111111}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "# Instantiation of local train set (and data loader)), baseline loss function, baseline model, default optimizer\n",
    "\n",
    "for i in [0,1,2,3]:\n",
    "    train_dataset = FedHeartDisease(center=i, train=True, pooled=False)\n",
    "    #print(len(train_dataset))\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "    lossfunc = BaselineLoss()\n",
    "    model = Baseline()\n",
    "    optimizer = Optimizer(model.parameters(), lr=LR)\n",
    "    print(len(train_dataset))\n",
    "    # Traditional pytorch training loop\n",
    "    for epoch in range(0, NUM_EPOCHS_POOLED):\n",
    "        for idx, (X, y) in enumerate(train_dataloader):\n",
    "            #print(len(y))\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X)\n",
    "            loss = lossfunc(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "    # Evaluation\n",
    "    from flamby.utils import evaluate_model_on_tests\n",
    "    # Instantiation of a list of the local test sets\n",
    "    test_dataloaders = [\n",
    "                torch.utils.data.DataLoader(\n",
    "                    FedHeartDisease(center=i, train=False, pooled=False),\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    shuffle=False,\n",
    "                    num_workers=0,\n",
    "                )\n",
    "                #for i in range(NUM_CLIENTS)\n",
    "            ]\n",
    "    print(len(train_dataloader), len(test_dataloaders))\n",
    "    # Function performing the evaluation\n",
    "    dict_cindex = evaluate_model_on_tests(model, test_dataloaders, metric)\n",
    "    print(dict_cindex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(FedHeartDisease(center=1, train=False, pooled=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
