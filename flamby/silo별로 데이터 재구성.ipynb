{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dbswldms316/FLamby/flamby/datasets/fed_tcga_brca/dataset.py:52: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return (torch.tensor(x, dtype=self.X_dtype), torch.tensor(y, dtype=self.y_dtype))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156\n",
      "** test dataset includes age groups like:  [13, 9, 79, 46, 7, 2]\n",
      "** test dataset after split:  [13, 134, 9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 476.52it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 82.28it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 745.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for age group 0 to 39: {'client_test_0': 0.6666666666666666}\n",
      "Results for age group 41 to 79: {'client_test_0': 0.6539735099337748}\n",
      "Results for age group 80 to 100: {'client_test_0': 0.5384615384615384}\n",
      "98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/dbswldms316/FLamby/flamby/datasets/fed_tcga_brca/dataset.py:52: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return (torch.tensor(x, dtype=self.X_dtype), torch.tensor(y, dtype=self.y_dtype))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** test dataset includes age groups like:  [5, 11, 55, 23, 2, 2]\n",
      "** test dataset after split:  [5, 89, 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1005.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 125.52it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1300.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for age group 0 to 39: {'client_test_0': 1.0}\n",
      "Results for age group 41 to 79: {'client_test_0': 0.710801393728223}\n",
      "Results for age group 80 to 100: {'client_test_0': 0.0}\n",
      "103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/dbswldms316/FLamby/flamby/datasets/fed_tcga_brca/dataset.py:52: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return (torch.tensor(x, dtype=self.X_dtype), torch.tensor(y, dtype=self.y_dtype))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** test dataset includes age groups like:  [9, 52, 36, 3, 3]\n",
      "** test dataset after split:  [9, 88, 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 680.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 128.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 845.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for age group 0 to 39: {'client_test_0': 0.6666666666666666}\n",
      "Results for age group 41 to 79: {'client_test_0': 0.7152542372881356}\n",
      "Results for age group 80 to 100: {'client_test_0': 1.0}\n",
      "81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/dbswldms316/FLamby/flamby/datasets/fed_tcga_brca/dataset.py:52: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return (torch.tensor(x, dtype=self.X_dtype), torch.tensor(y, dtype=self.y_dtype))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** test dataset includes age groups like:  [6, 11, 42, 20, 2]\n",
      "** test dataset after split:  [6, 73, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "No admissable pairs in the dataset.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 118\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# evaluate_model_on_tests 함수 호출\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 118\u001b[0m     dict_cindex_0_to_30 \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model_on_tests\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest_dataloader_0_to_30\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m     dict_cindex_40_to_60 \u001b[38;5;241m=\u001b[39m evaluate_model_on_tests(model, [test_dataloader_40_to_60], metric)\n\u001b[1;32m    120\u001b[0m     dict_cindex_70_to_100 \u001b[38;5;241m=\u001b[39m evaluate_model_on_tests(model, [test_dataloader_70_to_100], metric)\n",
      "File \u001b[0;32m~/FLamby/flamby/utils.py:71\u001b[0m, in \u001b[0;36mevaluate_model_on_tests\u001b[0;34m(model, test_dataloaders, metric, use_gpu, return_pred)\u001b[0m\n\u001b[1;32m     68\u001b[0m y_true_final \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(y_true_final)\n\u001b[1;32m     69\u001b[0m y_pred_final \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(y_pred_final)\n\u001b[0;32m---> 71\u001b[0m results_dict[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclient_test_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mmetric\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true_final\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_final\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_pred:\n\u001b[1;32m     74\u001b[0m     y_true_dict[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclient_test_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m y_true_final\n",
      "File \u001b[0;32m~/FLamby/flamby/datasets/fed_tcga_brca/metric.py:21\u001b[0m, in \u001b[0;36mmetric\u001b[0;34m(y_true, pred)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmetric\u001b[39m(y_true, pred):\n\u001b[1;32m      5\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calculates the concordance index (c-index) between a series of event\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m    times and a predicted score.\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m    The c-index is the average of how often a model says X is greater than Y\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m    c-index: float, calculating using the lifelines library\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     c_index \u001b[38;5;241m=\u001b[39m \u001b[43mlifelines\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcordance_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m c_index\n",
      "File \u001b[0;32m~/miniconda3/envs/flam/lib/python3.9/site-packages/lifelines/utils/concordance.py:94\u001b[0m, in \u001b[0;36mconcordance_index\u001b[0;34m(event_times, predicted_scores, event_observed)\u001b[0m\n\u001b[1;32m     91\u001b[0m event_times, predicted_scores, event_observed \u001b[38;5;241m=\u001b[39m _preprocess_scoring_data(event_times, predicted_scores, event_observed)\n\u001b[1;32m     92\u001b[0m num_correct, num_tied, num_pairs \u001b[38;5;241m=\u001b[39m _concordance_summary_statistics(event_times, predicted_scores, event_observed)\n\u001b[0;32m---> 94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_concordance_ratio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_correct\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_tied\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_pairs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/flam/lib/python3.9/site-packages/lifelines/utils/concordance.py:99\u001b[0m, in \u001b[0;36m_concordance_ratio\u001b[0;34m(num_correct, num_tied, num_pairs)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_concordance_ratio\u001b[39m(num_correct: \u001b[38;5;28mint\u001b[39m, num_tied: \u001b[38;5;28mint\u001b[39m, num_pairs: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m num_pairs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 99\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mZeroDivisionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo admissable pairs in the dataset.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (num_correct \u001b[38;5;241m+\u001b[39m num_tied \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m/\u001b[39m num_pairs\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: No admissable pairs in the dataset."
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/dbswldms316/FLamby/')\n",
    "\n",
    "from flamby.datasets.fed_tcga_brca.dataset import TcgaBrcaRaw, FedTcgaBrca\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "mydataset_raw = TcgaBrcaRaw()\n",
    "mydataset_pooled = FedTcgaBrca(train=True, pooled=True)\n",
    "\n",
    "from flamby.datasets.fed_tcga_brca import (\n",
    "    BATCH_SIZE,\n",
    "    LR,\n",
    "    NUM_EPOCHS_POOLED,\n",
    "    Baseline,\n",
    "    BaselineLoss,\n",
    "    metric,\n",
    "    NUM_CLIENTS,\n",
    "    Optimizer,\n",
    ")\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        # 여기서 필요한 전처리나 데이터 형태 변환을 수행합니다.\n",
    "        return sample\n",
    "\n",
    "import torch\n",
    "# Instantiation of local train set (and data loader)), baseline loss function, baseline model, default optimizer\n",
    "for i in [0,1,2,3,4,5]:\n",
    "    train_dataset = FedTcgaBrca(center=i, train=True, pooled=False)\n",
    "    test_dataset = FedTcgaBrca(center=i, train=False, pooled=False)\n",
    "    total_dataset = train_dataset + test_dataset\n",
    "    #print(len(total_dataset))\n",
    "    \n",
    "    age_groups = {}\n",
    "    for person in total_dataset:\n",
    "        age = int(person[0][0])\n",
    "        age_group = int(age - age % 10)\n",
    "        if age_group not in age_groups:\n",
    "            age_groups[age_group] = []\n",
    "        age_groups[age_group].append(person)\n",
    "    age_groups = dict(sorted(age_groups.items()))\n",
    "    \n",
    "    result_dict = {'0 to 30':[], '40 to 60':[], '70 to 100':[]}\n",
    "    for key in age_groups.keys():\n",
    "        if 0 < key <=30:\n",
    "            result_dict['0 to 30']+=(age_groups[key])\n",
    "        elif 30 < key <= 70:\n",
    "            result_dict['40 to 60']+=(age_groups[key])\n",
    "        else:\n",
    "            result_dict['70 to 100']+=(age_groups[key])\n",
    "    \n",
    "    i = len(result_dict['0 to 30'])\n",
    "    new_train_dataset = CustomDataset(result_dict['0 to 30'][:i//2]) \n",
    "    new_test_dataset = CustomDataset(result_dict['0 to 30'][i//2:]) \n",
    "    i = len(result_dict['40 to 60'])\n",
    "    new_train_dataset += CustomDataset(result_dict['40 to 60'][:i//2]) \n",
    "    new_test_dataset += CustomDataset(result_dict['40 to 60'][i//2:]) \n",
    "    i = len(result_dict['70 to 100'])\n",
    "    new_train_dataset += CustomDataset(result_dict['70 to 100'][:i//2]) \n",
    "    new_test_dataset += CustomDataset(result_dict['70 to 100'][i//2:]) \n",
    "    print(len(new_test_dataset))\n",
    "    \n",
    "    \n",
    "    lossfunc = BaselineLoss()\n",
    "    model = Baseline()\n",
    "    optimizer = Optimizer(model.parameters(), lr=LR)\n",
    "    new_train_dataloader = torch.utils.data.DataLoader(new_train_dataset, batch_size=16, shuffle=False)\n",
    "    \n",
    "    # Traditional pytorch training loop\n",
    "    for epoch in range(0, NUM_EPOCHS_POOLED):\n",
    "        for X,y in new_train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X)\n",
    "            loss = lossfunc(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    from flamby.utils import evaluate_model_on_tests\n",
    "    age_groups = {}\n",
    "    for person in new_test_dataset:\n",
    "        age = int(person[0][0])\n",
    "        age_group = age - age % 10\n",
    "        if age_group not in age_groups:\n",
    "            age_groups[age_group] = []\n",
    "        age_groups[age_group].append(person)\n",
    "    age_groups = dict(sorted(age_groups.items()))\n",
    "    \n",
    "    result_dict = {'0 to 30': [], '31 to 70': [], '71 to 100': []}\n",
    "    for key in age_groups.keys():\n",
    "        if key <= 30:\n",
    "            result_dict['0 to 30'] += age_groups[key]\n",
    "        elif key <= 70:\n",
    "            result_dict['31 to 70'] += age_groups[key]\n",
    "        else:\n",
    "            result_dict['71 to 100'] += age_groups[key]\n",
    "\n",
    "    print('** test dataset includes age groups like: ',[len(age_groups[i]) for i in age_groups.keys()])\n",
    "    print('** test dataset after split: ', [len(result_dict[i]) for i in result_dict.keys()])\n",
    "    \n",
    "    # 각 나이 범주에 해당하는 데이터셋 생성\n",
    "    test_dataset_0_to_30 = result_dict['0 to 30']\n",
    "    test_dataset_40_to_60 = result_dict['31 to 70']\n",
    "    test_dataset_70_to_100 = result_dict['71 to 100']\n",
    "\n",
    "    # 각 데이터셋을 DataLoader로 변환\n",
    "    test_dataloader_0_to_30 = torch.utils.data.DataLoader(test_dataset_0_to_30,  shuffle=False)\n",
    "    test_dataloader_40_to_60 = torch.utils.data.DataLoader(test_dataset_40_to_60,  shuffle=False)\n",
    "    test_dataloader_70_to_100 = torch.utils.data.DataLoader(test_dataset_70_to_100,  shuffle=False)\n",
    "    # evaluate_model_on_tests 함수 호출\n",
    "    with torch.no_grad():\n",
    "        dict_cindex_0_to_30 = evaluate_model_on_tests(model, [test_dataloader_0_to_30], metric)\n",
    "        dict_cindex_40_to_60 = evaluate_model_on_tests(model, [test_dataloader_40_to_60], metric)\n",
    "        dict_cindex_70_to_100 = evaluate_model_on_tests(model, [test_dataloader_70_to_100], metric)\n",
    "\n",
    "    # 결과 출력\n",
    "    print(\"Results for age group 0 to 39:\", dict_cindex_0_to_30)\n",
    "    print(\"Results for age group 41 to 79:\", dict_cindex_40_to_60)\n",
    "    print(\"Results for age group 80 to 100:\", dict_cindex_70_to_100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
